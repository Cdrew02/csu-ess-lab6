library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
# 2.1 List all CAMELS .txt files
file_paths <- list.files(
path       = "data/",
pattern    = "\\.txt$",
full.names = TRUE
)
library(tibble)
camels_raw <- reduce(
camels_list,
power_full_join,
.init = tibble(site_id = character()),  # empty tibble with correct key
by    = "site_id"
)
# Get full paths to all .txt files in the data/ directory
camels_files <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
library(readr)
library(purrr)
# Use map to read all files into a list of tibbles
camels_list <- map(camels_files, read_delim, delim = ";")
# Check names and structure of the list
names(camels_list) <- basename(camels_files)
str(camels_list, max.level = 1)
library(powerjoin)
# Provide an initial empty tibble with site_id for safe joining
library(tibble)
camels_raw <- reduce(
camels_list,
power_full_join,
by = "site_id",
.init = tibble(site_id = character())
)
glimpse(camels_raw)
summary(camels_raw)
# List all .txt files in data/ folder
camels_files <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
library(tidyverse)
library(powerjoin)
read_lines(camels_files[1], n_max = 5)
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
root  <- 'https://gdex.ucar.edu/dataset/camels/file'
download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf',
'data/camels_attributes_v2.0.pdf')
types <- c("clim", "geol", "soil", "topo", "vege", "hydro")
# Where the files live online ...
remote_files  <- glue('{root}/camels_{types}.txt')
install.packages("glue")
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
root  <- 'https://gdex.ucar.edu/dataset/camels/file'
download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf',
'data/camels_attributes_v2.0.pdf')
types <- c("clim", "geol", "soil", "topo", "vege", "hydro")
# Where the files live online ...
remote_files  <- glue('{root}/camels_{types}.txt')
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
# 2.1 List all CAMELS .txt files
file_paths <- list.files(
path       = "data/",
pattern    = "\\.txt$",
full.names = TRUE
)
# 2.2 Read into a named list via purrr::map()
camels_list <- file_paths %>%
set_names(tools::file_path_sans_ext(basename(.))) %>%
map(read_delim, delim = "\t", col_types = cols())
# 2.3 Iteratively fullâ€‘join all tables on "site_id"
camels_raw <- reduce(camels_list, power_full_join, by = "site_id")
# List all .txt files in your data folder
camels_files <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
library(readr)
library(purrr)
library(dplyr)
library(powerjoin)
# Get all .txt files in the data folder
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
# Read them into a named list
camels_list <- file_paths |>
set_names(basename(file_paths)) |>  # Give names like "camels_clim.txt"
map(~ read_delim(.x, delim = ";", show_col_types = FALSE))
# Ensure all data frames have "site_id" column
map(camels_list, ~ "site_id" %in% colnames(.x))
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
library(readr)
library(purrr)
library(dplyr)
library(powerjoin)
# Get all .txt files in the data folder
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_list <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE))
library(readr)
library(purrr)
library(dplyr)
# Step 1: List file paths
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
# Step 2: Load all text files into a named list
camels_list <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE))
# Step 3: Check which files contain 'site_id' column
map(camels_list, ~ "site_id" %in% colnames(.x))
map(camels_list, colnames)
library(readr)
library(purrr)
library(dplyr)
library(powerjoin)
# 1. Get full file paths for all .txt files
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
# 2. Read them in with the correct delimiter
camels_list <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_delim(.x, delim = ";", show_col_types = FALSE))
# 3. Check if all data frames now include 'gauge_id'
map(camels_list, ~ "gauge_id" %in% colnames(.x))
camels_raw <- reduce(camels_list, power_full_join, by = "gauge_id")
glimpse(camels_raw)
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
library(readr)
library(purrr)
library(dplyr)
library(powerjoin)
# Get all .txt files in the data folder
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_list <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE))
#| message: false
#| warning: false
library(tidyverse)
library(tidymodels)
library(skimr)
library(visdat)
library(ggpubr)
library(powerjoin)
library(patchwork)
library(readr)
library(purrr)
library(dplyr)
### Data Import/Tidy/Transform
# Get all .txt files in the data folder
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
# Read and join data
camels_raw <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE)) |>
power_full_join(by = "gauge_id", conflict = coalesce)
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
library(readr)
library(purrr)
library(dplyr)
library(powerjoin)
# Get all .txt files in the data folder
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_list <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE))
#| message: false
#| warning: false
# Data cleaning
camels_clean <- camels_raw |>
distinct() |>
na.omit() |>
mutate(across(where(is.character), as_factor))
visdat::vis_miss(camels_raw) # Visual check
### Data Splitting
set.seed(123)
split <- initial_split(camels_clean, prop = 0.8)
train <- training(split)
test <- testing(split)
### Feature Engineering
recipe <- recipe(q_mean ~ ., data = train) |>
step_rm(gauge_lat, gauge_lon, skip = TRUE) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
### Resampling and Model Testing
folds <- vfold_cv(train, v = 10)
# Define 3 models
lin_mod <- linear_reg() |> set_engine("lm")
rf_mod <- rand_forest() |> set_engine("ranger") |> set_mode("regression")
boost_mod <- boost_tree() |> set_engine("xgboost") |> set_mode("regression")
# Test models
model_set <- workflow_set(
preproc = list(recipe),
models = list(linear = lin_mod, rf = rf_mod, boost = boost_mod)
)
results <- model_set |>
workflow_map(resamples = folds, metrics = metric_set(rmse, rsq, mae))
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
library(readr)
library(purrr)
library(dplyr)
library(powerjoin)
# Get all .txt files in the data folder
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_list <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE))
#| message: false
#| warning: false
library(yardstick)  # Add this to your libraries section
# ... [previous code] ...
# Test models with explicit metric specification
results <- model_set |>
workflow_map(
resamples = folds,
metrics = metric_set(rmse, rsq, mae),
verbose = TRUE
)
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
library(readr)
library(purrr)
library(dplyr)
library(powerjoin)
# Get all .txt files in the data folder
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_list <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE))
#| message: false
#| warning: false
library(yardstick)  # Add this to your libraries section
#| message: false
#| warning: false
library(tidyverse)
library(tidymodels)
library(yardstick)   # Explicitly load for metrics
library(skimr)
library(visdat)
library(ggpubr)
library(powerjoin)
library(patchwork)
### Data Import/Tidy/Transform
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_raw <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE)) |>
power_full_join(by = "gauge_id", conflict = coalesce)
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
library(readr)
library(purrr)
library(dplyr)
library(powerjoin)
# Get all .txt files in the data folder
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_list <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE))
#| message: false
#| warning: false
library(yardstick)  # Add this to your libraries section
#| message: false
#| warning: false
library(tidyverse)
library(tidymodels)
library(yardstick)   # Explicitly load for metrics
library(skimr)
library(visdat)
library(ggpubr)
library(powerjoin)
library(patchwork)
### Data Import/Tidy/Transform
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_clean <- camels_raw |>
distinct() |>
na.omit() |>
mutate(across(where(is.character), as_factor))
### Data Splitting
set.seed(123)
split <- initial_split(camels_clean, prop = 0.8)
train <- training(split)
test <- testing(split)
### Feature Engineering
recipe <- recipe(q_mean ~ ., data = train) |>
step_rm(gauge_lat, gauge_lon, skip = TRUE) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
### Resampling and Model Testing
folds <- vfold_cv(train, v = 10)
lin_mod <- linear_reg() |> set_engine("lm")
rf_mod <- rand_forest() |> set_engine("ranger") |> set_mode("regression")
boost_mod <- boost_tree() |> set_engine("xgboost") |> set_mode("regression")
model_set <- workflow_set(
preproc = list(recipe),
models = list(linear = lin_mod, rf = rf_mod, boost = boost_mod)
)
results <- model_set |>
workflow_map(
resamples = folds,
metrics = metric_set(rmse, rsq, mae),
verbose = TRUE
)
library(tidyverse)    # for data wrangling, purrr, ggplot2, etc.
library(tidymodels)   # core modeling suite
library(skimr)        # EDA summaries
library(visdat)       # visualize missingness
library(ggpubr)       # enhanced ggplot2 themes
library(powerjoin)    # for power_full_join()
library(patchwork)    # combine ggplots
library(readr)
library(purrr)
library(dplyr)
library(powerjoin)
# Get all .txt files in the data folder
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_list <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_table(.x, show_col_types = FALSE))
#| message: false
#| warning: false
library(yardstick)  # Add this to your libraries section
#| message: false
#| warning: false
library(tidyverse)
library(tidymodels)
library(yardstick)   # Explicitly load for metrics
library(skimr)
library(visdat)
library(ggpubr)
library(powerjoin)
library(patchwork)
### Data Import/Tidy/Transform
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_clean <- camels_raw |>
distinct() |>
na.omit() |>
mutate(across(where(is.character), as_factor))
### Data Splitting
set.seed(123)
split <- initial_split(camels_clean, prop = 0.8)
train <- training(split)
test <- testing(split)
### Feature Engineering
recipe <- recipe(q_mean ~ ., data = train) |>
step_rm(gauge_lat, gauge_lon, skip = TRUE) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
### Resampling and Model Testing
folds <- vfold_cv(train, v = 10)
lin_mod <- linear_reg() |> set_engine("lm")
rf_mod <- rand_forest() |> set_engine("ranger") |> set_mode("regression")
boost_mod <- boost_tree() |> set_engine("xgboost") |> set_mode("regression")
model_set <- workflow_set(
preproc = list(recipe),
models = list(linear = lin_mod, rf = rf_mod, boost = boost_mod)
)
results <- model_set |>
workflow_map(
resamples = folds,
metrics = metric_set(rmse, rsq, mae),
verbose = TRUE
)
# Update metrics specification in both workflow_map() and tune_grid()
results <- model_set |>
workflow_map(
resamples = folds,
metrics = metric_set(yardstick::rmse, yardstick::rsq, yardstick::mae),
verbose = TRUE
)
# Update metrics specification in both workflow_map() and tune_grid()
results <- model_set |>
workflow_map(
resamples = folds,
metrics = metric_set(yardstick::rmse, yardstick::rsq, yardstick::mae),
verbose = TRUE
)
# Update metrics specification in both workflow_map() and tune_grid()
results <- model_set |>
workflow_map(
resamples = folds,
metrics = metric_set(yardstick::rmse, yardstick::rsq, yardstick::mae),
verbose = TRUE
)
# Update metrics specification in both workflow_map() and tune_grid()
results <- model_set |>
workflow_map(
resamples = folds,
metrics = metric_set(yardstick::rmse, yardstick::rsq, yardstick::mae),
verbose = TRUE
)
# Update critical packages
install.packages(c("tidymodels", "yardstick", "workflowsets"))
#| message: false
#| warning: false
#| results: show
# Load Required Libraries
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(skimr)
library(visdat)
library(patchwork)
library(ggpubr)
# Data Import/Tidy/Transform -----------------------------------------------
file_paths <- list.files("data/", pattern = "\\.txt$", full.names = TRUE)
camels_raw <- file_paths |>
set_names(basename(file_paths)) |>
map(~ read_delim(.x, delim = " ", show_col_types = FALSE)) |>
power_full_join(by = "gauge_id", conflict = coalesce)
# Change from generic "data/" to explicit path
file_paths <- list.files("Lab 6/data/", pattern = "\\.txt$", full.names = TRUE)
# After joining, verify column names exist
stopifnot("q_mean" %in% names(camels_clean))
#| message: false
#| warning: false
# Load Required Packages --------------------------------------------------
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(skimr)
library(visdat)
library(patchwork)
library(yardstick)
# Data Import -------------------------------------------------------------
# Correct path for your file structure
file_paths <- list.files("Lab 6/data/", pattern = "\\.txt$", full.names = TRUE)
# Validate file loading
stopifnot("Should have 6 CAMELS files" = length(file_paths) == 6)
file_paths <- list.files("Lab 6/Lab 6/data/", pattern = "\\.txt$", full.names = TRUE)
file_paths <- list.files("Lab 6/Lab 6/data/", pattern = "\\.txt$", full.names = TRUE)
file_paths <- list.files("Lab 6/Lab 6/data/", pattern = "\\.txt$", full.names = TRUE)
#| message: false
#| warning: false
# Load Required Packages --------------------------------------------------
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(skimr)
library(visdat)
library(patchwork)
library(yardstick)
# Data Import -------------------------------------------------------------
# Correct path for nested folder structure
file_paths <- list.files("Lab 6/Lab 6/data/",
pattern = "\\.txt$",
full.names = TRUE)
# Diagnostic output
cat("Found", length(file_paths), "CAMELS files:\n")
print(basename(file_paths))
# Validation (should show 6 files)
stopifnot("Should have 6 CAMELS files" = length(file_paths) == 6)
